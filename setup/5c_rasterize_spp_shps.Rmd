---
title: 'Process IUCN spp shapes'
author: "*Compiled on `r date()` by `r Sys.info()['user']`*"
output: 
  html_document:
    code_folding: hide
    toc: true
    toc_depth: 3
    toc_float: yes
    number_sections: true
    theme: cerulean
    highlight: haddock
    includes: 
      in_header: '~/github/src/templates/ohara_hdr.html'
  pdf_document:
    toc: true
---

``` {r setup, echo = TRUE, message = FALSE, warning = FALSE}

knitr::opts_chunk$set(fig.width = 6, fig.height = 4, fig.path = 'Figs/',
                      echo = TRUE, message = FALSE, warning = FALSE)

library(raster)
library(rgeos)
source('https://raw.githubusercontent.com/oharac/src/master/R/common.R')  ###
  ### includes library(tidyverse); library(stringr); dir_M points to ohi directory
library(sf)

dir_git <- here()

source(file.path(dir_git, '_setup/common_fxns.R'))

dir_bli <- file.path(dir_M, 'git-annex/globalprep/_raw_data/birdlife_intl/d2018')
dir_shp <- file.path(dir_M, 'git-annex/globalprep/_raw_data/iucn_spp/d2018-1')
  ### These are shapefiles directly from IUCN as individual species map files
  ### (in the unzipped folder).
  ### in this folder are shapefiles at a taxonomic level.


```

# Summary

Using a set of IUCN species range maps, rasterize each species to 10 km x 10 km raster using `fasterize`.  Use `presence` field from shapefile.

* Subpopulation polygons must be identified and rasterized separately from the parent polygon; this must be done by sciname and subpop fields since the polygon IDs are based upon the parent ID.
* Regional assessments need not be determined at this stage - the ID numbers match the global ID numbers (including subpops).

# Data source

IUCN Red List: Spatial Data Download
IUCN: Gina Ralph direct communication

# Methods

## Read spp shapes, correct subpop IDs, `fasterize()`, depth clip, save to csv

We will loop over each species in each shapefile and rasterize separately, using `sf` and `fasterize` packages.  

* From the full map list, filter to a single shapefile
* Load shapefile using `st_read`, and correct subpop IDs from `shp_iucn_sid` to `iucn_sid`
* Loop over each `iucn_sid` in the shapefile, rasterizing (`fasterize()`) to 10 km^2 resolution, using "presence" field. 
    * clip to neritic (<=200 m) and shallow (<=60 m) depth raster if appropriate.  Otherwise mask to bathy raster.  Since bathy raster was created by masking to area raster, cells with any marine presence will be kept but any non-marine cells will be dropped.
    * Save as .tif and .csv, and compare average file sizes.  .csv easier to work with, but might be significantly larger than .tifs in the long run.
        * note: no longer saving as .tif for speed and file size - just use .csv instead!
    * use `mclapply()` to speed this up.
    
``` {r rasterize and clip and save to csv}

reload <- FALSE

maps_to_rasterize <- read_csv(file.path(dir_data,
                                        sprintf('spp_marine_maps_%s.csv', api_version)),
                              col_types = 'ddcicccl') %>%
  mutate(shp_file = str_replace(dbf_file, 'dbf$', 'shp'))

### rast_base for cell IDs
rast_base <- raster(file.path(dir_spatial, 'cell_id_rast.tif'))

### If some species already processed, remove from the list to process.
if(reload == FALSE) {
  maps_already_rasterized <- list.files(file.path(dir_o_anx, 'spp_rasters'),
                                        pattern = '.csv') %>%
    str_replace_all('iucn_sid_|.csv$', '') %>%
    as.integer()

  maps_to_rasterize <- maps_to_rasterize %>%
    filter(!iucn_sid %in% maps_already_rasterized)
}

### for selectively rerunning taxonomic groups
# maps_to_rasterize <- maps_to_rasterize %>%
#   filter(str_detect(dbf_file, 'CHONDR'))
# 
# asdf <- paste0('iucn_sid_', maps_to_rasterize$iucn_sid, '.csv')
# zxcv <- list.files(file.path(dir_o_anx, 'spp_rasters'), 
#                    full.names = TRUE, 
#                    pattern = paste0(asdf, collapse = '|'))
# zzz <- file.mtime(zxcv)
# tmp_df <- data.frame(f = zxcv,
#                      t = zzz)
# 2018-09-12 12:38:31 check to make sure they're all later than this!

if(nrow(maps_to_rasterize) == 0) { ### all maps accounted for as .csvs
  
  cat_msg('reload == ', reload, '... No maps to process...')
  
} else {
  
  cat_msg('reload == ', reload, '... Maps to process: ', nrow(maps_to_rasterize))

  ### These will be used as masks
  rast_bathy <- raster(file.path(dir_spatial,
                                 'bathy_rast.tif'))
  rast_neritic <- raster(file.path(dir_spatial,
                                 'bathy_rast_neritic.tif'))
  rast_shallow <- raster(file.path(dir_spatial,
                                 'bathy_rast_shallow.tif'))
  
  ################################################################.
  ### Loop over each distinct shapefile with species range maps
  ################################################################.
  shps <- maps_to_rasterize$shp_file %>% unique()
  for(i in seq_along(shps)) {
    ### i <- 1
    
    shp <- shps[i]
    
    maps_in_shp <- maps_to_rasterize %>%
      filter(shp_file == shp)
    
    id_fix <- maps_in_shp %>%
      select(shp_iucn_sid, iucn_sid, subpop, max_depth) %>%
      distinct()
    
    cat_msg(i, ' of ', length(shps), ': reading ', basename(shp), ' from: \n  ', shp)

    polys_all <- read_sf(shp, type = 6) %>%
      clean_df_names()
      ### we will check geoms and fix them inside the mclapply, 
      ### and then reproject, one species at a time

    if(!'sciname' %in% names(polys_all)) {
      polys_all <- polys_all %>%
        rename(sciname = binomial)
    }
    
    if(!'subpop' %in% names(polys_all)) {
      polys_all$subpop <- NA_character_
      ### if shape doesn't have subpop column, add it as NA
    }
    if('id_no' %in% names(polys_all)) {
      polys_all <- polys_all %>%
        rename(iucn_sid = id_no)
    }
    if(!'presence' %in% names(polys_all)) {
      polys_all <- polys_all %>%
        mutate(presence = 1)
    }

    
    polys_match <- polys_all %>%
      select(shp_iucn_sid = iucn_sid, sciname, subpop, presence, geometry) %>%
      mutate(presence = ifelse(presence == 0, 1, presence),
             subpop   = as.character(subpop)) %>%
      inner_join(id_fix, by = c('shp_iucn_sid', 'subpop')) 
    
    spp_ids <- maps_in_shp$iucn_sid %>% 
      sort() %>% 
      unique()
    
  
    ####################################################################.
    ### In each shapefile, loop over each species ID using mclapply().
    ####################################################################.
    
    cat_msg('Processing ', basename(shp), ' with ', length(spp_ids), ' species...')
    
    # system.time({
      tmp <- parallel::mclapply(seq_along(spp_ids),
                                mc.cores = 24, 
                                FUN = function(x) {
        ### x <- 1
        spp <- spp_ids[x]
        
        cat_msg(x, ' of ', length(spp_ids), ': Processing ', spp, ' in ', basename(shp),
                ' (group ', i, ' of ', length(shps), ')...\n')
        
        spp_shp <- polys_match %>%
          filter(iucn_sid == spp)
        
        spp_shp <- valid_check(spp_shp)
          ### if invalid geom, and bounds exceeded, buffer to 0
        spp_shp <- spp_shp %>%
          clip_to_globe() %>%
            ### indiv files should have adjusted boundaries already; only 
            ### files from Spatial Data Download should run into this
          st_transform(gp_proj4)
        
        spp_rast <- fasterize::fasterize(spp_shp, rast_base, field = 'presence', fun = 'min')
        
        ### depth clip if necessary; otherwise clip to bathy raster (which previously
        ### was clipped to area raster - so cells with any marine area will be kept,
        ### and non-marine cells will be dropped)
        if(spp_shp$max_depth == '< 20 m') {
          spp_rast <- mask(spp_rast, rast_shallow)
        } else if(spp_shp$max_depth == '< 200 m') {
          spp_rast <- mask(spp_rast, rast_neritic)
        } else {
          spp_rast <- mask(spp_rast, rast_bathy)
        }
        ### write out as a raster:
        # rast_file <- file.path(dir_o_anx, sprintf('spp_rasters/iucn_sid_%s.tif', spp))
        # raster::writeRaster(spp_rast, rast_file, overwrite = TRUE)
        ### See note below about file size; rasters are larger than csvs in general
        
        ### convert to dataframe and write out as a csv:
        spp_present <- data.frame(cell_id  = values(rast_base),
                                  presence = values(spp_rast)) %>%
          filter(!is.na(presence))
        
        if(nrow(spp_present) == 0) {
          cat_msg('Species ID ', spp, ' resulted in a zero-length dataframe.')
        }
        
        write_csv(spp_present, file.path(dir_o_anx, 'spp_rasters',
                                         sprintf('iucn_sid_%s.csv', spp)))
        
        return(NA)
      }) ### end of mclapply FUN definition
    # }) ### end of system.time call
  } ### end of for loop over each species group
} ### end of "if" check to make sure there are any maps to rasterize

```

``` {r file size testing}

maps <- read_csv(file.path(dir_data,
                           sprintf('spp_marine_maps_%s.csv', api_version)),
                 col_types = 'ddciccc') %>%
  select(spp_group = dbf_file, iucn_sid, sciname, subpop) %>%
  mutate(spp_group = str_replace(spp_group, '.dbf', '')) %>%
  distinct()

csvs <- list.files(file.path(dir_o_anx, 'spp_rasters')) %>%
  str_replace_all('iucn_sid_|.csv', '')

x <- list.files(file.path(dir_o_anx, 'spp_rasters'),
                full.names = TRUE)
x <- x[str_detect(x, paste0(csvs, collapse = '|'))]

y <- file.info(x) %>%
  mutate(f = basename(rownames(.)),
         type = ifelse(str_detect(f, 'csv$'), 'csv', 'tif'),
         iucn_sid = str_replace_all(f, 'iucn_sid_|.(csv|tif)', ''),
         iucn_sid = as.integer(iucn_sid)) %>%
  left_join(maps, by = 'iucn_sid')

z <- y %>%
  group_by(type, spp_group) %>%
  summarize(mean_size = mean(size), n_spp = n()) %>%
  spread(type, mean_size) %>%
  # mutate(ratio = tif / csv) %>%
  ungroup() %>%
  arrange(desc(csv))

# sum(z$tif * z$n_spp) ### 8,146,818,040:  8.1 GB for 5369 spp (pre depth clip) (some dupes, oops)
# sum(z$csv * z$n_spp) ### 3,179,096,927:  3.2 GB for 5369 spp (pre depth clip) (some dupes, oops)
# sum(z$csv * z$n_spp) ### 2,218,041,470:  2.2 GB for 5332 spp (post depth clip) (dupes removed!)

zz <- data.frame(spp_group = 'TOTAL: all available spp maps',
                n_spp = sum(z$n_spp),
                csv   = sum(z$csv * z$n_spp)) %>%
  bind_rows(z)

DT::datatable(zz, caption = 'Mean file size by group and type')

```


